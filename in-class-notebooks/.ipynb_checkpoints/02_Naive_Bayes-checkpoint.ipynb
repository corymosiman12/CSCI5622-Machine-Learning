{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2: Naive Bayes\n",
    "***\n",
    "\n",
    "<img src=\"figs/bayes.jpg\" width=1201 height=50> \n",
    "\n",
    "<!---\n",
    "![my_image](files/figs/bayes.jpg)\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prob1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prob2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Naive Bayes on Symbols\n",
    "***\n",
    "\n",
    "> This problem was adopted from [Naive Bayes and Text Classification I: Introduction and Theory](https://arxiv.org/abs/1410.5329) by Sebastian Raschka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following training set of 12 symbols which have been labeled as either + or -: \n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"figs/shapes.png\" width=500>\n",
    "\n",
    "\n",
    "Answer the following questions: \n",
    "\n",
    "\n",
    "**A**: What are the general features associated with each training example? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Shape: {circle, square}  \n",
    "Color: {green, red, blue}  \n",
    "Symbol: {+, -}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part, we'll use Naive Bayes to classify the following test example: \n",
    "\n",
    "<img src=\"figs/bluesquare.png\" width=200>\n",
    "\n",
    "OK, so this symbol actually appears in the training set, but let's pretend that it doesn't.  \n",
    "\n",
    "The decision rule can be defined as \n",
    "\n",
    ">Classify ${\\bf x}$ as + if <br>\n",
    ">$p(+ ~|~ {\\bf x} = [blue,~ square]) \\geq p(- ~|~ {\\bf x} = [blue, ~square])$ <br>\n",
    ">else classify sample as -\n",
    "\n",
    "**B**: What are the Maximum Likelihood Estimates of the priors $p(+)$ and $p(-)$? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "$$\n",
    "p(+) = \\frac{\\#~instances~of~positive}{\\#~total~instances} = \\frac{7}{12}\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(-) = \\frac{\\#~instances~of~negative}{\\#~total~instances} = \\frac{5}{12}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C**: Identify and compute estimates of the class-conditional probabilities required to predict the class of ${\\bf x} = [blue,~square]$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "The Naive Bayes approach assumes that features are **CONDITIONALLY INDEPENDENT**.  Conditional independence can be summarized as follows: \n",
    "\n",
    "Just a bit about notation: $$p([blue, square]) = p(blue \\cap square)$$  \n",
    "independence means:\n",
    "$$\n",
    "p([blue, square]) = p(blue)*p(square)\n",
    "$$\n",
    "\n",
    "The best way to think about it is to break it down into a table as follows:\n",
    "\n",
    "| +      | -      |\n",
    "|--------|--------|\n",
    "| R, sq  | B, sq  |\n",
    "| B, cir | B, sq  |\n",
    "| G, sq  | R, cir |\n",
    "| B, cir | B, cir |\n",
    "| R, sq  | R, sq  |\n",
    "| G, sq  |        |\n",
    "| B, sq  |        |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "relating to class-conditional probabilities:\n",
    "\n",
    "$$\n",
    "p(+ ~|~ {\\bf x} = [blue,~ square])~=~\\frac{p(~[blue, square]~|~+)*p(~+)}{p(~[blue, square]~)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(~[blue, square]~|~+) = p(~blue~|~+)*p(~square~|~+)\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(~blue~|~+)~=~\\frac{3}{7}\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(~square~|~+)~=~\\frac{5}{7}\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(~blue~|~-)~=~\\frac{3}{5}\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(~square~|~-)~=~\\frac{3}{5}\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(~blue~)~=~\\frac{6}{12}\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(~square~)~=~\\frac{8}{12}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D**: Using the estimates computed above, compute the **posterior** scores for each label, and find the Naive Bayes prediction of the label for ${\\bf x} = [blue,~square]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**  \n",
    "$$\n",
    "\\frac{p(~[blue, square]~|~+)*p(~+)}{p(~[blue, square]~)}=~\\frac{\\frac{3}{7}~*~\\frac{5}{7}~*~\\frac{7}{12}}{\\frac{6}{12}~*~\\frac{8}{12}}~=~0.536\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{p(~[blue, square]~|~-)*p(~-)}{p(~[blue, square]~)}=~\\frac{\\frac{3}{5}~*~\\frac{3}{5}~*~\\frac{5}{12}}{\\frac{6}{12}~*~\\frac{8}{12}}~=~0.450\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the Naive Bayesian prediction for ${\\bf x} = [blue,~square]$ would be ${\\bf+}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E**: If you haven't already, compute the class-conditional probabilities scores $\\hat{p}({\\bf x} = [blue,~square] ~|~ +)$ and $\\hat{p}({\\bf x} = [blue,~square] ~|~ -)$ under the Naive Bayes assumption.  How can you reconsile these values with the final prediction that would made? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "$$\n",
    "\\hat{p}({\\bf x} = [blue,~square] ~|~ +) = p(blue ~|~ +) * p(square ~|~ +) = \\frac{3}{7}*\\frac{5}{7} = 0.31\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{p}({\\bf x} = [blue,~square] ~|~ -) = p(blue ~|~ -) * p(square ~|~ -) = \\frac{3}{5}*\\frac{3}{5} = 0.36\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prob3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Laplace Smoothing \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the same training set from Problem 2, but suppose we see the following test example: \n",
    "    \n",
    "<img src=\"figs/greencircle.png\" width=200>\n",
    "\n",
    "Before you get too far into trying to predict the label of the green circle, look carefully at the training set.  Notice that there are no green shapes labeled - in the training set, so when we try to compute the class-conditional probability $p(green ~|~ -)$ we'll get a zero probability.  To fix this, you'll implement Laplace smoothing. Notice that this is a little different than the SPAM vs HAM example shown in the video.  We actually have two very different features in shapes and colors. We'll apply Laplace Smoothing to the shape and color class-conditional probabilities separately. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**: What would the general formula for the estimate of $p(shape ~|~ class)$ with Laplace Smoothing look like for the given training set?  What is the *vocabulary* in the shape case?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer: **\n",
    "Vocabulary: {square, circle}  \n",
    "General formula: $p(shape ~|~ class) = \\frac{#(shape ~and~ class)+1}{#class + 1*2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B**: What would the general formula for the estimate of $p(color ~|~ class)$ with Laplace Smoothing look like for the given training set?  What is the *vocabulary* in the shape case?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer: **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C**: Predict the label for the green circle using the Laplaced smoothed class-conditional probability formulas.  Don't forget to apply Laplace Smoothing to the priors as well! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer: **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prob4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Unknown Features\n",
    "***\n",
    "\n",
    "Once again consider the training set from Problem 2, but suppose we see the following test example: \n",
    "    \n",
    "<img src=\"figs/yellowsquare.png\" width=200>\n",
    "\n",
    "OK, this is a weird one.  Up until this point, we've never seen the color *yellow*, and thus don't include it in the color vocabulary.  One way that we could handle this is to add to the color vocabulary, and then recompute the the class-conditional probabilities with *yellow* included in the vocabulary. \n",
    "\n",
    "But what happens when on the next test example we see a *pink* circle (or worse, a triangle)? We'd rather not continue to modify our probability estimates whenever we see shape or color that we haven't see before.  One solution to this is to just assume we'll see weird things in the future and combine all of the posibilities into an UNK feature. If we do this, then our class-conditional probabilities become \n",
    "\n",
    "$$\n",
    "p(feature ~|~ class) = \\frac{\\#~instances~of~feature~in~class + 1}{\\#~total~symbols~in~class + |V| + 1}\n",
    "$$\n",
    "\n",
    "where here the vocabular $V$ is the same vocabular defined by the training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**: Predict the label of the yellow square.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prob1ans'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "### Helper Functions \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".MathJax nobr>span.math>span{border-left-width:0 !important};\n",
    "</style>\n",
    "\"\"\")\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
